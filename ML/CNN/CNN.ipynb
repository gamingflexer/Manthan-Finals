{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e3d15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef996dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a9ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change this acc\n",
    "\n",
    "X = df.iloc[:, :100*100].values.reshape(-1, 100, 100, 1) \n",
    "y = df.iloc[:, -1].values\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec539f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes= 1+ df.loc[:, 'class'].unique().shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb82059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.random.randint(100*100)\n",
    "plt.imshow(X[q][:,:,0], cmap='gray')\n",
    "plt.title(f'Label-{np.argmax(y[q])}')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f19b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X, y, random_state=42, test_size=0.15)\n",
    "\n",
    "print(f'Train Size - {X_train.shape}\\nTest Size - {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d385539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificially increase training set\n",
    "train_datagen = ImageDataGenerator(rescale=1./255.,\n",
    "                                   rotation_range=10,\n",
    "                                   width_shift_range=0.25,\n",
    "                                   height_shift_range=0.25,\n",
    "                                   shear_range=0.1,\n",
    "                                   zoom_range=0.25,\n",
    "                                   horizontal_flip=False)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8000b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb3217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "model_name = 'Face_trained_model_'+datetime.now().strftime(\"%H_%M_%S_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c26407",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name = model_name)\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(100, 100, 1)))\n",
    "model.add(BatchNormalization()) #----------------\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization()) #----------------\n",
    "model.add(Conv2D(64, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization()) #----------------\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2)) #----------------\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e114435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = RMSprop(lr=learning_rate)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c0ccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=200,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.2)\n",
    "\n",
    "ch = ModelCheckpoint('models/'+model_name+'.h5', monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=200)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/\"+datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8753ade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 256\n",
    "history = model.fit_generator(train_datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                              steps_per_epoch= X_train.shape[0]//batch_size,\n",
    "                              epochs=epochs,\n",
    "                              validation_data=valid_datagen.flow(X_test, y_test),\n",
    "                              validation_steps=50,\n",
    "                              verbose = 1,\n",
    "                              callbacks=[learning_rate_reduction, es, ch, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc5fbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(valid_datagen.flow(X_test, y_test))\n",
    "\n",
    "print(f'Loss: {loss}\\nAccuracy: {acc*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba909bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & test accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & test loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c9f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f265e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa87dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(model.predict(X_test),axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c7964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize weights to HDF5\n",
    "model.save(model_name+\".h5\")\n",
    "print(\"Model Saved to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c14ae07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e45751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d6dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349f22cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
